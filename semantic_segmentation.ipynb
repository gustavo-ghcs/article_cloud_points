{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 1: Importar as bibliotecas necess√°rias\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#for vizualisation purposes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 2: Definir os caminhos e carregar os dados\n",
    "#create paths and load data\n",
    "data_folder=\"cloud_points/\"\n",
    "result_folder=\"cloud_points\"\n",
    "\n",
    "#Load the file\n",
    "DATANAME=\"3DML_urban_point_cloud.xyz\"\n",
    "\n",
    "#Store in a Pandas dataframe the content of the file\n",
    "pcd=pd.read_csv(data_folder+DATANAME,delimiter=' ')\n",
    "#Clean the dataframe, and drop all the line that contains a NaN (Not a Number) value.\n",
    "pcd.dropna(inplace=True)\n",
    "pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Passo 3: Selecionar e preparar\n",
    "#Create training and testing\n",
    "labels=pcd['Classification']\n",
    "features=pcd[['X','Y','Z','R','G','B']]\n",
    "features_scaled = MinMaxScaler().fit_transform(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will take a lot of time\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "clf = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(C=0.01, penalty=\"l1\", dual=False))),\n",
    "  ('classification', RandomForestClassifier())\n",
    "])\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No, scaling is not necessary for random forests. The nature of RF is such that convergence and numerical precision issues, which can sometimes trip up the algorithms used in logistic and linear regression, as well as neural networks, aren't so important\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 10)\n",
    "\n",
    "#The line below is useful only if you want to create a classification model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "#The line below is useful only if you want to test on an unseen dataset (real scenario)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, rf_predictions, target_names=['ground','vegetation','buildings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results 3D\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(X_test['X'], X_test['Y'], X_test['Z'], c = rf_predictions, s=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
    "axs[0].scatter(X_test['X'], X_test['Y'], c =y_test, s=0.05)\n",
    "axs[0].set_title('3D Point Cloud Ground Truth')\n",
    "axs[1].scatter(X_test['X'], X_test['Y'], c = rf_predictions, s=0.05)\n",
    "axs[1].set_title('3D Point Cloud Predictions')\n",
    "axs[2].scatter(X_test['X'], X_test['Y'], c = y_test-rf_predictions, cmap = plt.cm.rainbow, s=0.5*(y_test-rf_predictions))\n",
    "axs[2].set_title('Differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4: Treinar e testar o modelo\n",
    "#Example of a K-Nearest Neighbors Model for 3D Point Cloud Semantic Segmentation\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "knn_predictions = knn_classifier.predict(X_test)\n",
    "print(classification_report(y_test, knn_predictions, target_names=['ground','vegetation','buildings']))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
    "axs[0].scatter(X_test['X'], X_test['Y'], c =y_test, s=0.05)\n",
    "axs[0].set_title('3D Point Cloud Ground Truth')\n",
    "axs[1].scatter(X_test['X'], X_test['Y'], c = knn_predictions, s=0.05)\n",
    "axs[1].set_title('3D Point Cloud Predictions')\n",
    "axs[2].scatter(X_test['X'], X_test['Y'], c = y_test-knn_predictions, cmap = plt.cm.rainbow, s=0.5*(y_test-knn_predictions))\n",
    "axs[2].set_title('Differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of a Multi-Layer Perception Model for 3D Point Cloud Semantic Segmentation\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_classifier = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(15, 2), random_state=1)\n",
    "mlp_classifier.fit(X_train, y_train)\n",
    "mlp_predictions = mlp_classifier.predict(X_test)\n",
    "print(classification_report(y_test, mlp_predictions, target_names=['ground','vegetation','buildings']))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,5)) # row 1, col 2 index 1\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].scatter(X_test['X'], X_test['Y'], c =y_test, s=0.05)\n",
    "axs[0].set_title('3D Point Cloud Ground Truth')\n",
    "axs[1].scatter(X_test['X'], X_test['Y'], c = mlp_predictions, s=0.05)\n",
    "axs[1].set_title('3D Point Cloud Predictions')\n",
    "axs[2].scatter(X_test['X'], X_test['Y'], c = y_test-mlp_predictions, cmap = plt.cm.rainbow, s=0.5*(y_test-mlp_predictions))\n",
    "axs[2].set_title('Differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 4: Performance do modelo\n",
    "val_dataset=\"3DML_validation.xyz\"\n",
    "val_pcd=pd.read_csv(data_folder+val_dataset,delimiter=' ')\n",
    "val_pcd.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels=val_pcd['Classification']\n",
    "val_features=val_pcd[['X','Y','Z','R','G','B']]\n",
    "val_predictions = rf_classifier.predict(val_features)\n",
    "print(classification_report(val_labels, val_predictions, target_names=['ground','vegetation','buildings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(20,5)) # row 1, col 2 index 1\n",
    "# fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].scatter(val_features['X'], val_features['Y'], c =val_labels, s=0.05)\n",
    "axs[0].set_title('3D Point Cloud Ground Truth')\n",
    "axs[1].scatter(val_features['X'], val_features['Y'], c = val_predictions, s=0.05)\n",
    "axs[1].set_title('3D Point Cloud Predictions')\n",
    "axs[2].scatter(val_features['X'], val_features['Y'], c = val_labels-val_predictions, cmap = plt.cm.rainbow, s=0.5*(val_labels-val_predictions))\n",
    "axs[2].set_title('Differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pcd['Classification']\n",
    "features=pcd[['Z','R','G','B','omnivariance_2','normal_cr_2','NumberOfReturns','planarity_2','omnivariance_1','verticality_1']]\n",
    "features_scaled = MinMaxScaler().fit_transform(features)\n",
    "\n",
    "val_labels=val_pcd['Classification']\n",
    "val_features=val_pcd[['Z','R','G','B','omnivariance_2','normal_cr_2','NumberOfReturns','planarity_2','omnivariance_1','verticality_1']]\n",
    "val_features_scaled = MinMaxScaler().fit_transform(val_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.4)\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 10)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "print(classification_report(y_test, rf_predictions, target_names=['ground','vegetation','buildings']))\n",
    "\n",
    "val_rf_predictions = rf_classifier.predict(val_features_scaled)\n",
    "print(classification_report(val_labels, val_rf_predictions, target_names=['ground','vegetation','buildings']))\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
    "axs[0].scatter(val_pcd['X'], val_pcd['Y'], c =val_labels, s=0.05)\n",
    "axs[0].set_title('3D Point Cloud Ground Truth')\n",
    "axs[1].scatter(val_pcd['X'], val_pcd['Y'], c = val_rf_predictions, s=0.05)\n",
    "axs[1].set_title('3D Point Cloud Predictions')\n",
    "axs[2].scatter(val_pcd['X'], val_pcd['Y'], c = val_labels-val_rf_predictions, cmap = plt.cm.rainbow, s=0.5*(val_labels-val_rf_predictions))\n",
    "axs[2].set_title('Differences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels=val_pcd['Classification']\n",
    "val_features=val_pcd[['Z','R','G','B','omnivariance_2','normal_cr_2','NumberOfReturns','planarity_2','omnivariance_1','verticality_1']]\n",
    "val_features_sampled, val_features_test, val_labels_sampled, val_labels_test = train_test_split(val_features, val_labels, test_size=0.9)\n",
    "val_features_scaled_sample = MinMaxScaler().fit_transform(val_features_test)\n",
    "\n",
    "labels=pd.concat([pcd['Classification'],val_labels_sampled])\n",
    "features=pd.concat([pcd[['Z','R','G','B','omnivariance_2','normal_cr_2','NumberOfReturns','planarity_2','omnivariance_1','verticality_1']],val_features_sampled])\n",
    "features_scaled = MinMaxScaler().fit_transform(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, labels, test_size=0.4)\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 10)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, rf_predictions, target_names=['ground','vegetation','buildings']))\n",
    "\n",
    "\n",
    "val_rf_predictions_90 = rf_classifier.predict(val_features_scaled_sample)\n",
    "print(classification_report(val_labels_test, val_rf_predictions_90, target_names=['ground','vegetation','buildings']))\n",
    "\n",
    "\n",
    "val_features_scaled = MinMaxScaler().fit_transform(val_features)\n",
    "val_rf_predictions = rf_classifier.predict(val_features_scaled)\n",
    "print(classification_report(val_labels, val_rf_predictions, target_names=['ground','vegetation','buildings']))\n",
    "\n",
    "# val_pcd['predictions']=val_rf_predictions\n",
    "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
    "axs[0].scatter(val_pcd['X'], val_pcd['Y'], c =val_pcd['Classification'], s=0.05)\n",
    "axs[0].set_title('3D Point Cloud Ground Truth')\n",
    "axs[1].scatter(val_pcd['X'], val_pcd['Y'], c = val_rf_predictions, s=0.05)\n",
    "axs[1].set_title('3D Point Cloud Predictions')\n",
    "axs[2].scatter(val_pcd['X'], val_pcd['Y'], c = val_pcd['Classification']-val_rf_predictions, cmap = plt.cm.rainbow, s=0.5*(val_pcd['Classification']-val_rf_predictions))\n",
    "axs[2].set_title('Differences')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
